{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from kats.consts import TimeSeriesData\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from kats.utils.simulator import Simulator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from kats.tsfeatures.tsfeatures import TsFeatures\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Simulator(n=90, freq=\"D\", start = \"2021-01-01\") # simulate 90 days of data\n",
    "random_seed = 100\n",
    "\n",
    "# generate 10 TimeSeriesData with arima_sim\n",
    "np.random.seed(random_seed) # setting numpy seed\n",
    "arima_sim_list = [sim.arima_sim(ar=[0.1, 0.05], ma = [0.04, 0.1], d = 1) for _ in range(10)]\n",
    "\n",
    "# generate 10 TimeSeriesData with trend shifts\n",
    "trend_sim_list = [\n",
    "    sim.trend_shift_sim(\n",
    "        cp_arr = [30, 60, 75],\n",
    "        trend_arr=[3, 15, 2, 8],\n",
    "        intercept=30,\n",
    "        noise=50,\n",
    "        seasonal_period=7,\n",
    "        seasonal_magnitude=np.random.uniform(10, 100),\n",
    "        random_seed=random_seed\n",
    "    ) for _ in range(10)\n",
    "]\n",
    "\n",
    "\n",
    "# generate 10 TimeSeriesData with level shifts\n",
    "level_shift_list = [\n",
    "    sim.level_shift_sim(\n",
    "        cp_arr = [30, 60, 75],\n",
    "        level_arr=[1.35, 1.05, 1.35, 1.2],\n",
    "        noise=0.05,\n",
    "        seasonal_period=7,\n",
    "        seasonal_magnitude=np.random.uniform(0.1, 1.0),\n",
    "        random_seed=random_seed\n",
    "    ) for _ in range(10)\n",
    "]\n",
    "\n",
    "ts_list = arima_sim_list + trend_sim_list + level_shift_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:Holt-Winters failed Data must be positive.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "ts = ts_list[0]\n",
    "# Step 1. initiate TsFeatures\n",
    "model = TsFeatures()\n",
    "\n",
    "# Step 2. use .transform() method, and apply on the target time series data\n",
    "output_features = model.transform(ts)\n",
    "len(output_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import logging\n",
    "from unittest import TestCase\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ax.modelbridge.registry import Models, SearchSpace\n",
    "from ax.service.utils.instantiation import parameter_from_json\n",
    "from kats.consts import TimeSeriesData\n",
    "from kats.models.arima import ARIMAModel\n",
    "from kats.models.holtwinters import HoltWintersModel\n",
    "from kats.models.metalearner.get_metadata import GetMetaData\n",
    "from kats.models.metalearner.metalearner_hpt import MetaLearnHPT\n",
    "from kats.models.metalearner.metalearner_modelselect import (\n",
    "    MetaLearnModelSelect,\n",
    ")\n",
    "from kats.models.metalearner.metalearner_predictability import (\n",
    "    MetaLearnPredictability,\n",
    ")\n",
    "from kats.models.prophet import ProphetModel\n",
    "from kats.models.sarima import SARIMAModel\n",
    "from kats.models.stlf import STLFModel\n",
    "from kats.models.theta import ThetaModel\n",
    "from kats.tsfeatures.tsfeatures import TsFeatures\n",
    "\n",
    "\n",
    "DATA = pd.DataFrame(\n",
    "    {\n",
    "        \"time\": pd.date_range(\"2020-05-06\", periods=60, freq=\"D\"),\n",
    "        \"y\": np.arange(1, 61),\n",
    "    }\n",
    ")\n",
    "TSData = TimeSeriesData(DATA)\n",
    "\n",
    "# TS which is too short\n",
    "TSData_short = TimeSeriesData(DATA.iloc[:8, :])\n",
    "\n",
    "# TS which has constant values only\n",
    "DATA_const = DATA.copy()\n",
    "DATA_const[\"y\"] = 1\n",
    "TSData_const = TimeSeriesData(DATA_const)\n",
    "\n",
    "# TS which has NAN values\n",
    "DATA_nan = DATA.copy()\n",
    "DATA_nan.iloc[10, 1] = np.nan\n",
    "TSData_nan = TimeSeriesData(DATA_nan)\n",
    "\n",
    "# TS which has INF values\n",
    "DATA_inf = DATA.copy()\n",
    "DATA_inf.iloc[10, 1] = np.inf\n",
    "TSData_inf = TimeSeriesData(DATA_inf)\n",
    "\n",
    "# TS which doesn't have constant frequency\n",
    "DATA_gap = DATA.copy()\n",
    "DATA_gap = DATA_gap.drop([3, 4])\n",
    "TSData_gap = TimeSeriesData(DATA_gap)\n",
    "\n",
    "# TS which is not univariate\n",
    "DATA_multi = pd.DataFrame(\n",
    "    {\n",
    "        \"time\": pd.date_range(\"2020-05-06\", periods=60, freq=\"D\"),\n",
    "        \"y\": np.arange(1, 61),\n",
    "        \"z\": np.random.randn(60),\n",
    "    }\n",
    ")\n",
    "TSData_multi = TimeSeriesData(DATA_multi)\n",
    "\n",
    "# Base Models\n",
    "base_models = {\n",
    "    \"arima\": ARIMAModel,\n",
    "    \"holtwinters\": HoltWintersModel,\n",
    "    \"sarima\": SARIMAModel,\n",
    "    \"prophet\": ProphetModel,\n",
    "    \"stlf\": STLFModel,\n",
    "    \"theta\": ThetaModel,\n",
    "}\n",
    "\n",
    "\n",
    "def generate_test_ts():\n",
    "    # time series with negative data, which contains Nan for TsFeatures\n",
    "    time = pd.date_range(\"2020-05-06\", \"2020-11-17\", freq=\"D\")\n",
    "    ts = pd.DataFrame(np.random.randn(len(time)), columns=[\"value\"])\n",
    "    ts[\"time\"] = time\n",
    "    ts1 = TimeSeriesData(ts)\n",
    "    # predictable time series\n",
    "    ts = pd.DataFrame(np.abs(np.random.randn(len(time))), columns=[\"value\"])\n",
    "    ts[\"time\"] = time\n",
    "    ts2 = TimeSeriesData(ts)\n",
    "    return (ts1, ts2)\n",
    "\n",
    "\n",
    "def generate_meta_data(n):\n",
    "    # generate meta data to initialize MetaLearnModelSelect\n",
    "    spaces = {m: base_models[m].get_parameter_search_space() for m in base_models}\n",
    "\n",
    "    m = len(base_models)\n",
    "    res = np.abs(np.random.uniform(0, 1.0, n * m)).reshape(n, -1)\n",
    "    features = np.random.randn(n * 40).reshape(n, -1)\n",
    "    generators = {\n",
    "        m: Models.UNIFORM(\n",
    "            SearchSpace([parameter_from_json(item) for item in spaces[m]])\n",
    "        )\n",
    "        for m in spaces\n",
    "    }\n",
    "    models = list(base_models.keys())\n",
    "    ans = []\n",
    "    for i in range(n):\n",
    "        hpt = {}\n",
    "        j = 0\n",
    "        for m in base_models:\n",
    "            hpt[m] = (generators[m].gen(1).arms[0].parameters, res[i, j])\n",
    "            j += 1\n",
    "        ans.append(\n",
    "            {\n",
    "                \"hpt_res\": hpt,\n",
    "                \"best_model\": np.random.choice(models),\n",
    "                \"features\": {str(k): features[i, k] for k in range(features.shape[1])},\n",
    "            }\n",
    "        )\n",
    "    return ans\n",
    "\n",
    "\n",
    "def generate_meta_data_by_model(model, n, d=40):\n",
    "    model = model.lower()\n",
    "    if model in base_models:\n",
    "        model = base_models[model]\n",
    "    space = model.get_parameter_search_space()\n",
    "    generator = Models.UNIFORM(\n",
    "        SearchSpace([parameter_from_json(item) for item in space])\n",
    "    )\n",
    "    x = np.random.randn(n * d).reshape(n, -1)\n",
    "    x = pd.DataFrame(x)\n",
    "    y = [generator.gen(1).arms[0].parameters for i in range(n)]\n",
    "    y = pd.DataFrame(y)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def equals(v1, v2):\n",
    "    # check whether v1 and v2 are equal\n",
    "    try:\n",
    "        if isinstance(v1, pd.DataFrame):\n",
    "            return v1.equals(v2)\n",
    "        elif isinstance(v1, np.ndarray):\n",
    "            return np.array_equal(v1, v2)\n",
    "        elif isinstance(v1, list) and (len(v1) == len(v2)):\n",
    "            comp = [equals(v1[i], v2[i]) for i in range(len(v1))]\n",
    "            return np.sum(comp) == len(comp)\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        msg = \"fail to compare the inputs and exception message is \" + e\n",
    "        raise ValueError(msg)\n",
    "\n",
    "\n",
    "class testMetaLearner(TestCase):\n",
    "    def test_get_meta_data(self) -> None:\n",
    "        # test GetMetaData using a simple case\n",
    "        metadata = GetMetaData(data=TSData, num_trials=2, num_arms=1)\n",
    "        res = metadata.get_meta_data()\n",
    "\n",
    "        # test meta data output\n",
    "        self.assertEqual(\n",
    "            list(res.keys()),\n",
    "            [\"hpt_res\", \"features\", \"best_model\", \"search_method\", \"error_method\"],\n",
    "        )\n",
    "\n",
    "        # test meta data output - HPT part\n",
    "        self.assertEqual(\n",
    "            list(res[\"hpt_res\"].keys()),\n",
    "            [\"arima\", \"holtwinters\", \"prophet\", \"theta\", \"stlf\", \"sarima\"],\n",
    "        )\n",
    "\n",
    "    def test_inputdata_errors(self) -> None:\n",
    "        # test input data error (time series' type is not TimeSeriesData)\n",
    "        self.assertRaises(ValueError, GetMetaData, DATA)\n",
    "\n",
    "        # test input data error (time series is not univariate)\n",
    "        self.assertRaises(ValueError, GetMetaData, TSData_multi)\n",
    "\n",
    "        # test input data error (time series is too short)\n",
    "        self.assertRaises(ValueError, GetMetaData, TSData_short)\n",
    "\n",
    "        # test input data error (time series only contains constant value)\n",
    "        self.assertRaises(ValueError, GetMetaData, TSData_const)\n",
    "\n",
    "        # test input data error (time series contains nan)\n",
    "        self.assertRaises(ValueError, GetMetaData, TSData_nan)\n",
    "\n",
    "        # test input data error (time series contains inf)\n",
    "        self.assertRaises(ValueError, GetMetaData, TSData_inf)\n",
    "\n",
    "        # test input data error (time series doesn't have constant freq)\n",
    "        self.assertRaises(ValueError, GetMetaData, TSData_gap)\n",
    "\n",
    "\n",
    "class MetaLearnModelSelectTest(TestCase):\n",
    "    def test_initialize(self) -> None:\n",
    "\n",
    "        self.assertRaises(ValueError, MetaLearnModelSelect, [])\n",
    "\n",
    "        self.assertRaises(ValueError, MetaLearnModelSelect, [{}] * 40)\n",
    "\n",
    "        self.assertRaises(ValueError, MetaLearnModelSelect, [{\"hpt_res\": [None]}] * 40)\n",
    "\n",
    "        self.assertRaises(\n",
    "            ValueError,\n",
    "            MetaLearnModelSelect,\n",
    "            [{\"hpt_res\": [None], \"features\": [None]}] * 40,\n",
    "        )\n",
    "\n",
    "        self.assertRaises(\n",
    "            ValueError,\n",
    "            MetaLearnModelSelect,\n",
    "            [{\"hpt_res\": [1.0], \"features\": {\"f\": 1.0}, \"best_model\": \"best\"}] * 40,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = generate_meta_data(n=35)\n",
    "mlms = MetaLearnModelSelect(samples)\n",
    "\n",
    "# Test preprocess\n",
    "mlms.preprocess(downsample=True, scale=True)\n",
    "\n",
    "# Test rescale\n",
    "mtx = mlms.metadataX.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "np.sum(np.abs(np.average(mtx, axis=0)) < 1e-10), mtx.shape[1],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "np.sum(np.abs(np.std(mtx, axis=0) - 1) < 1e-8), mtx.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlms.train(method=\"RandomForest\")\n",
    "# Test prediction consistency\n",
    "t1, t2 = generate_test_ts()\n",
    "t2_df = t2.to_dataframe().copy()\n",
    "pred = mlms.pred(t2)\n",
    "pred_fuzzy = mlms.pred_fuzzy(t2)\n",
    "pred_all = mlms.pred(t2, n_top=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:Holt-Winters failed Data must be positive.\n",
      "WARNING:root:Features of the test time series contains NaN value, consider processing it. Features are: {'length': 196, 'mean': -0.025344996505505136, 'var': 0.16092352950067676, 'entropy': 0.9131205531168675, 'lumpiness': 0.0026013206755497753, 'stability': 0.0016049332573627167, 'flat_spots': 1, 'hurst': -0.008376960184714293, 'std1st_der': 0.3123979576435772, 'crossing_points': 104, 'binarize_mean': 0.5102040816326531, 'unitroot_kpss': 0.023698218520389162, 'heterogeneity': 8.316033519190968, 'histogram_mode': -0.060337561945063234, 'linearity': 4.391456685377164e-05, 'trend_strength': 0.22284999896554203, 'seasonality_strength': 0.39457356732522075, 'spikiness': 2.82558765785192e-07, 'peak': 1, 'trough': 5, 'level_shift_idx': 171, 'level_shift_size': 0.07983604377134768, 'y_acf1': 0.008560187427106366, 'y_acf5': 0.020075187211989184, 'diff1y_acf1': -0.4231158017938481, 'diff1y_acf5': 0.2252294075786934, 'diff2y_acf1': -0.5730417537522824, 'diff2y_acf5': 0.34554890204774774, 'y_pacf5': 0.01943121689243676, 'diff1y_pacf5': 0.5151594669483368, 'diff2y_pacf5': 0.9795333690949274, 'seas_acf1': 0.007150215389230971, 'seas_pacf1': -0.0018384317919040167, 'firstmin_ac': 2, 'firstzero_ac': 2, 'holt_alpha': 1.4901161193847656e-08, 'holt_beta': 1.4901161193847656e-08, 'hw_alpha': nan, 'hw_beta': nan, 'hw_gamma': nan}. Fill in NaNs with 0.\n"
     ]
    }
   ],
   "source": [
    "if pred != pred_fuzzy[\"label\"][0] or pred != pred_all[0]:\n",
    "    msg = f\"Prediction is not consistent! Results are: self.pred: {pred}, self.pred_fuzzy: {pred_fuzzy}, self.pred(, n_top=2): {pred_all}\"\n",
    "    logging.error(msg)\n",
    "    raise ValueError(msg)\n",
    "# Test case for time series with nan features\n",
    "_ = mlms.pred(t1)\n",
    "# Test pred_by_feature and its consistency\n",
    "feature = np.random.randn(3 * mlms.metadataX.shape[1]).reshape(3, -1)\n",
    "feature2 = feature.copy()\n",
    "pred = mlms.pred_by_feature(feature)\n",
    "pred_all = mlms.pred_by_feature(feature, n_top=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Multi-task neural network structure:\n",
      "MultitaskNet(\n",
      "  (shared_layer): ModuleList(\n",
      "    (0): Linear(in_features=40, out_features=40, bias=True)\n",
      "  )\n",
      "  (cat_layer_combo): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): Linear(in_features=40, out_features=5, bias=True)\n",
      "      (1): Linear(in_features=5, out_features=2, bias=True)\n",
      "    )\n",
      "    (1): ModuleList(\n",
      "      (0): Linear(in_features=40, out_features=5, bias=True)\n",
      "      (1): Linear(in_features=5, out_features=2, bias=True)\n",
      "    )\n",
      "    (2): ModuleList(\n",
      "      (0): Linear(in_features=40, out_features=2, bias=True)\n",
      "      (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "    )\n",
      "    (3): ModuleList(\n",
      "      (0): Linear(in_features=40, out_features=3, bias=True)\n",
      "      (1): Linear(in_features=3, out_features=2, bias=True)\n",
      "    )\n",
      "    (4): ModuleList(\n",
      "      (0): Linear(in_features=40, out_features=5, bias=True)\n",
      "      (1): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "    (5): ModuleList(\n",
      "      (0): Linear(in_features=40, out_features=5, bias=True)\n",
      "      (1): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "    (6): ModuleList(\n",
      "      (0): Linear(in_features=40, out_features=5, bias=True)\n",
      "      (1): Linear(in_features=5, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (num_layer): ModuleList()\n",
      ")\n",
      "WARNING:root:Holt-Winters failed Data must be positive.\n",
      "WARNING:root:Time series features contain NaNs!Time series features are {'length': 196, 'mean': -0.05064560504297275, 'var': 0.17544065311037546, 'entropy': 0.8973361308795784, 'lumpiness': 0.0020387009359529597, 'stability': 0.009419154819023874, 'flat_spots': 1, 'hurst': 0.0019503232062871051, 'std1st_der': 0.2886731015559849, 'crossing_points': 89, 'binarize_mean': 0.5102040816326531, 'unitroot_kpss': 0.035174707434624676, 'heterogeneity': 8.834881760591296, 'histogram_mode': -0.21008068189600837, 'linearity': 0.015570373309115851, 'trend_strength': 0.3192753646144807, 'seasonality_strength': 0.37841703971456175, 'spikiness': 3.673434643112348e-07, 'peak': 1, 'trough': 3, 'level_shift_idx': 154, 'level_shift_size': 0.08459899740486458, 'y_acf1': 0.1014777021959719, 'y_acf5': 0.027151472750527324, 'diff1y_acf1': -0.47476213628939107, 'diff1y_acf5': 0.2371421681968911, 'diff2y_acf1': -0.6506735610610347, 'diff2y_acf5': 0.4473827436792338, 'y_pacf5': 0.027048285360922807, 'diff1y_pacf5': 0.4274215377371293, 'diff2y_pacf5': 1.0440303513850464, 'seas_acf1': -0.07821451216933853, 'seas_pacf1': -0.0695898015638256, 'firstmin_ac': 2, 'firstzero_ac': 4, 'holt_alpha': 1.490116119557297e-08, 'holt_beta': 1.6604584471280057e-09, 'hw_alpha': nan, 'hw_beta': nan, 'hw_gamma': nan}. Fill in NaNs with 0.\n"
     ]
    }
   ],
   "source": [
    "t1, t2 = generate_test_ts()\n",
    "t2_df = t2.to_dataframe().copy()\n",
    "feature1 = np.random.randn(3 * 40).reshape(3, -1)\n",
    "feature2 = [np.random.randn(40), np.random.randn(40)]\n",
    "feature3 = pd.DataFrame(np.random.randn(3 * 40).reshape(3, -1))\n",
    "feature1_copy, feature2_copy, feature3_copy = (\n",
    "    feature1.copy(),\n",
    "    list(feature2),\n",
    "    feature3.copy(),\n",
    ")\n",
    "for model in [\"prophet\"]:\n",
    "    x, y = generate_meta_data_by_model(model, 150, 40)\n",
    "    # Check default models initialization and training\n",
    "    mlhpt = MetaLearnHPT(x, y, default_model=model)\n",
    "    mlhpt.get_default_model()\n",
    "    # self.assertRaises(ValueError, mlhpt.build_network, [20])\n",
    "    mlhpt.build_network()\n",
    "    mlhpt.train()\n",
    "    # Test case for time series with nan features\n",
    "    _ = (mlhpt.pred(t1).parameters[0],)\n",
    "    mlhpt.pred(t2)\n",
    "    mlhpt.pred_by_feature(feature1)\n",
    "    mlhpt.pred_by_feature(feature2)\n",
    "    mlhpt.pred_by_feature(feature3)\n",
    "    # Check prediction consistency:\n",
    "    dict1 = mlhpt.pred(t2).parameters[0]\n",
    "    t2.value /= t2.value.max()\n",
    "    dict2 = mlhpt.pred_by_feature(pd.DataFrame([TsFeatures().transform(t2)]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "len(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast, Dict\n",
    "features = cast(Dict[str, float], TsFeatures(hw_params=False).transform(ts))\n",
    "expected = {\n",
    "    # statistics_features\n",
    "    \"length\": 25.0,\n",
    "    \"mean\": 0.0,\n",
    "    \"var\": 1.0,\n",
    "    \"entropy\": 0.8808,\n",
    "    \"lumpiness\": 0.2423,\n",
    "    \"stability\": 0.0148,\n",
    "    \"flat_spots\": 1.0,\n",
    "    \"hurst\": -1.3972,\n",
    "    \"std1st_der\": 0.618,\n",
    "    \"crossing_points\": 10.0,\n",
    "    \"binarize_mean\": 0.16,\n",
    "    \"unitroot_kpss\": 0.1567,\n",
    "    \"heterogeneity\": 3.1459,\n",
    "    \"histogram_mode\": -0.4543,\n",
    "    \"linearity\": 0.0,\n",
    "    # stl_features\n",
    "    \"trend_strength\": 0.5364,\n",
    "    \"seasonality_strength\": 0.4646,\n",
    "    \"spikiness\": 0.0004,\n",
    "    \"peak\": 6.0,\n",
    "    \"trough\": 5.0,\n",
    "    # level_shift_features\n",
    "    \"level_shift_idx\": 0.0,\n",
    "    \"level_shift_size\": 0.0046,\n",
    "    # acfpacf_features\n",
    "    \"y_acf1\": 0.2265,\n",
    "    \"y_acf5\": 0.1597,\n",
    "    \"diff1y_acf1\": -0.5021,\n",
    "    \"diff1y_acf5\": 0.3465,\n",
    "    \"diff2y_acf1\": -0.6838,\n",
    "    \"diff2y_acf5\": 0.6092,\n",
    "    \"y_pacf5\": 0.2144,\n",
    "    \"diff1y_pacf5\": 0.4361,\n",
    "    \"diff2y_pacf5\": 4.4276,\n",
    "    \"seas_acf1\": -0.1483,\n",
    "    \"seas_pacf1\": -0.0064,\n",
    "    # special_ac\n",
    "    \"firstmin_ac\": 4.0,\n",
    "    \"firstzero_ac\": 4.0,\n",
    "    # holt_params\n",
    "    \"holt_alpha\": 0.0,\n",
    "    \"holt_beta\": 0.0\n",
    "    # hw_params\n",
    "    # cusum_detector\n",
    "    # robust_stat_detector\n",
    "    # bocp_detector\n",
    "    # outlier_detector\n",
    "    # trend_detector\n",
    "    # nowcasting\n",
    "    # seasonalities\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'length': 90,\n",
       " 'mean': -4.973228083549793,\n",
       " 'var': 50.69499812650379,\n",
       " 'entropy': 0.2742447620827895,\n",
       " 'lumpiness': 10.258210327109449,\n",
       " 'stability': 45.07760417461487,\n",
       " 'flat_spots': 1,\n",
       " 'hurst': 0.4188436896564726,\n",
       " 'std1st_der': 0.8773588739369633,\n",
       " 'crossing_points': 5,\n",
       " 'binarize_mean': 0.43333333333333335,\n",
       " 'unitroot_kpss': 0.41641147078333335,\n",
       " 'heterogeneity': 73.29527168434541,\n",
       " 'histogram_mode': -11.841676172131818,\n",
       " 'linearity': 0.8346355269096618,\n",
       " 'trend_strength': 0.9853025999592567,\n",
       " 'seasonality_strength': 0.3521955818150291,\n",
       " 'spikiness': 0.00020455870537077636,\n",
       " 'peak': 1,\n",
       " 'trough': 6,\n",
       " 'level_shift_idx': 23,\n",
       " 'level_shift_size': 0.7134342301151566,\n",
       " 'y_acf1': 0.9597578784708428,\n",
       " 'y_acf5': 4.0361834721280365,\n",
       " 'diff1y_acf1': 0.1830233735938267,\n",
       " 'diff1y_acf5': 0.0794760417768679,\n",
       " 'diff2y_acf1': -0.4816907863327952,\n",
       " 'diff2y_acf5': 0.24476824866108501,\n",
       " 'y_pacf5': 0.9862593061001352,\n",
       " 'diff1y_pacf5': 0.07981792144706332,\n",
       " 'diff2y_pacf5': 0.36145785941160113,\n",
       " 'seas_acf1': 0.8149983814152568,\n",
       " 'seas_pacf1': 0.030344962550473743,\n",
       " 'firstmin_ac': 53,\n",
       " 'firstzero_ac': 30,\n",
       " 'holt_alpha': 0.9999999850988388,\n",
       " 'holt_beta': 0.13656078692385917}"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "samples = generate_meta_data(n=35)\n",
    "mlms = MetaLearnModelSelect(samples)\n",
    "\n",
    "# Test preprocess\n",
    "mlms.preprocess(downsample=True, scale=True)\n",
    "\n",
    "# Test rescale\n",
    "mtx = mlms.metadataX.values\n",
    "\n",
    "# test variable-wise zero-mean\n",
    "np.sum(np.abs(np.average(mtx, axis=0)) < 1e-10), mtx.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "len(np.unique(list(collections.Counter(mlms.metadataY).values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test variable-wise unit std\n",
    "np.sum(np.abs(np.std(mtx, axis=0) - 1) < 1e-8), mtx.shape[1]\n",
    "\n",
    "# Test train\n",
    "mlms.train(method=\"RandomForest\")\n",
    "# Test prediction consistency\n",
    "t1, t2 = generate_test_ts()\n",
    "t2_df = t2.to_dataframe().copy()\n",
    "pred = mlms.pred(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}